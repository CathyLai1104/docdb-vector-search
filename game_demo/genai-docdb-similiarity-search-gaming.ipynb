{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01cb58e",
   "metadata": {},
   "source": [
    "# Building AI-powered search in Amazon DocumentDB Vector Search using Amazon Bedrock and DocumentDB Vector Search\n",
    "_**Using Bedrock Titan embedding model and DocumentDB `Vector Search` for similarity search on Game recommendations**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Bedrock Model Call Preparation](#Bedrock-model-call-prepration)\n",
    "1. [DocumentDB](#DocumentDB-vector-search)\n",
    "1. [Evaluate Search Results](#Evaluate-DocumentDB-vector-Search-Results)\n",
    "\n",
    "## Background\n",
    "\n",
    "In this notebook, we'll build the core components of a textually similar Products. Often people don't know what exactly they are looking for and in that case they just type an item description and hope it will retrieve similar items.\n",
    "\n",
    "One of the core components of searching textually similar items is a fixed length sentence/word embedding i.e. a  “feature vector” that corresponds to that text. The reference word/sentence embedding typically are generated offline and must be stored so they can be efficiently searched. In this use case we are using Amazon Bedrock Titan(https://aws.amazon.com/cn/bedrock/titan/).\n",
    "\n",
    "To enable efficient searches for textually similar items, we'll use Amazon Bedrock Titan to generate fixed length sentence embeddings i.e “feature vectors” and use the Nearest Neighbor search in Amazon DocumentDB (with MongoDB compatibility) using the Vector Search. DocumentDB Vector Search lets you store and search for points in vector space and find the \"nearest neighbors\" for those points. Use cases include recommendations (for example, an \"other songs you might like\" feature in a music application), image recognition, and fraud detection.\n",
    "\n",
    "Here are the steps we'll follow to build textually similar items: After some initial setup, we'll call Bedrock Titan Embedding model. Then generate feature vectors for games from the website(https://mechanicbase.com/cars/different-car-models-types) dataset. Those feature vectors will be stored in DocumentDB Vector Search vector datatype. Next, we'll explore some sample text queries, and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7045906",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install required python libraries for the workshop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a8a7e4-568a-4463-abce-638139b8c294",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U pymongo  tqdm boto3 requests scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3283ad62",
   "metadata": {},
   "source": [
    "### Downloading Gaming demo data\n",
    "\n",
    "The dataset itself consists of 29 high-resolution images, each depicting a type of car. Each of the images has five textual description. \n",
    "\n",
    "**Downloading Gaming Demo data**: Data originally from here: https://store.steampowered.com/charts/mostplayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395da9f-0561-4e34-9205-a1071d1561cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.request≈\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from multiprocessing import cpu_count\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "filename = 'metadata.json'\n",
    "\n",
    "with open(filename) as json_file:\n",
    "    results = json.load(json_file)\n",
    "if not os.path.exists(filename):\n",
    "   print (\"metadata.json file not exits\")\n",
    "results[0]\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60502e",
   "metadata": {},
   "source": [
    "## Bedrock Model Call Preparation\n",
    "prepare for Bedrock Titan model call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2f4ef-841d-4f10-af88-dba06520caf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for bedrock model call\n",
    "%pip install langchain==0.0.305 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41d1d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for bedrock model call\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e41c3fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for bedrock model call\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\",\n",
    "                                       client=bedrock_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2025a03e-ff71-4bee-b4e3-f7fcc981729b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Up Claude Parameters\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "inference_modifier = {'max_tokens_to_sample':4096, \n",
    "                      \"temperature\":1,\n",
    "                      \"top_k\":250,\n",
    "                      \"top_p\":1,\n",
    "                      \"stop_sequences\": [\"\\n\\nHuman\"]\n",
    "                     }\n",
    "\n",
    "textgen_llm = Bedrock(model_id = \"anthropic.claude-v2:1\",\n",
    "                    client = bedrock_client, \n",
    "                    model_kwargs = inference_modifier \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6b609a1-5562-4ea4-9822-23de43a7b131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate your LLM execution time\n",
    "import time\n",
    "\n",
    "def timer_llm(prompt, if_print=1):\n",
    "    start_time = time.time()\n",
    "    response = textgen_llm(prompt)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    if if_print == 1:\n",
    "        print(\"----------------------------------------- OutPut -----------------------------------------\")\n",
    "        print(\"Elapsed time: \", elapsed_time, \"seconds\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ba6cf8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for Bedrock Embedding model call\n",
    "\n",
    "def generate_embeddings(data):\n",
    "    r = bedrock_embeddings.embed_query(data)\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e107d",
   "metadata": {},
   "source": [
    "## DocumentDB Vector Search\n",
    "\n",
    "vector search for Amazon DocumentDB (with MongoDB compatibility), a new built-in capability that lets you store, index, and search millions of vectors with millisecond response times within your document database.\n",
    "\n",
    "One of the key benefits of using pgvector is that it allows you to perform similarity searches on large datasets quickly and efficiently. This is particularly useful in industries like e-commerce, where businesses need to be able to quickly search through large product catalogs to find the items that best match a customer's preferences. It supports exact and approximate nearest neighbor search, L2 distance, inner product, and cosine distance.\n",
    "\n",
    "To further optimize your searches, you can also use DocumentDB Vector Search's indexing features. By creating indexes on your vector data, you can speed up your searches and reduce the amount of time it takes to find the nearest neighbors to a given vector.\n",
    "\n",
    "In this step we'll get all the translated product descriptions of *__zalandoresearch__* dataset and store those embeddings into DocumentDB Vector Search vector type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7daae42f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up a connection to your Amazon DocumentDB (MongoDB compatibility) cluster and creating the database\n",
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient(\n",
    "\"docdb-vector-search-lab.cluster-cd4xami2mmof.us-east-1.docdb.amazonaws.com:27017\",\n",
    "username=\"masteruser\",\n",
    "password=\"Password1\",\n",
    "retryWrites=False,\n",
    "tls='true',\n",
    "tlsCAFile='global-bundle.pem')\n",
    "db = client.similarity6\n",
    "collection = db.games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdce09a-ac28-46b6-a2eb-b262fdadf057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import boto3 \n",
    "import json \n",
    "\n",
    "\n",
    "for x in results:\n",
    "    description1 = ' '.join(x.get('descriptions', []))\n",
    "    vector = generate_embeddings(description1)\n",
    "    record = { \"name\": x.get('name'),\n",
    "              \"description\": ' '.join(x.get('descriptions', [])),\n",
    "              \"recommendation\":x.get('recommendation'),\n",
    "          \"url\": x.get('url'),\n",
    "          \"descriptions_embeddings\": vector}\n",
    "    print(\"record\",record)\n",
    "    rec_id1 = collection.insert_one(record)  \n",
    "\n",
    "collection.create_index ([(\"descriptions_embeddings\",\"vector\")], vectorOptions={\n",
    "\"lists\": 1,\n",
    "\"similarity\": \"euclidean\",\n",
    "\"dimensions\": 1536}) \n",
    "client.close()\n",
    "\n",
    "#print (\"Vector embeddings has been successfully loaded into DocumentDB\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a93851",
   "metadata": {},
   "source": [
    "## Evaluate DocumentDB vector Search Results\n",
    "\n",
    "In this step we will use SageMaker realtime inference to generate embeddings for the query and use the embeddings to search the DocumentDB to retrive the nearest neighbours and retrive the relevent product images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aefb95e-35b2-451f-ad72-19726ef15fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "p_base = '''\n",
    "\\n\\nHuman:\n",
    "你是一个游戏推荐员. 你的目标是按照<instructions>重写接下来的游戏名称，游戏类别，游戏介绍，并根据用户的主机配置以及用户是否是未成年人进行游戏推荐.\n",
    "\n",
    "重写要求<instructions>\n",
    "1. 写出游戏名称\n",
    "2. 列出游戏类别\n",
    "3. 优化总结游戏介绍\n",
    "4. 指出玩该游戏需要的主机配置\n",
    "5. 判断是否适合未成年人玩\n",
    "</instructions>\n",
    "参考内容为:\n",
    "'''\n",
    "\n",
    "def similarity_search(search_text):\n",
    "    client = pymongo.MongoClient(\n",
    "    \"docdb-vector-search-lab.cluster-cd4xami2mmof.us-east-1.docdb.amazonaws.com:27017\",\n",
    "    username=\"masteruser\",\n",
    "    password=\"Password1\",\n",
    "    retryWrites=False,\n",
    "    tls='true',\n",
    "    tlsCAFile='global-bundle.pem')\n",
    "    db = client.similarity6\n",
    "    collection = db.games\n",
    "    \n",
    "    data = {\"inputs\": search_text}\n",
    "    print(data)\n",
    "    res1 = generate_embeddings(data['inputs'])\n",
    "    \n",
    "    query = {\"vectorSearch\" : {\"vector\" : res1, \"path\": \"descriptions_embeddings\", \"similarity\": \"euclidean\", \"k\": 2}}\n",
    "    projection = {\n",
    "    \"_id\":0,\n",
    "    \"name\":1,\n",
    "    \"recommendation\":1,\n",
    "    \"url\":1,\n",
    "    \"description\":1,\n",
    "    \"descriptions_embeddings\": 1}\n",
    "    r = collection.aggregate([{'$search': query},{\"$project\": projection}])\n",
    "    \n",
    "  \n",
    "    urls = []\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    \n",
    "    for x in r:\n",
    "        response= timer_llm(p_base +\"游戏名称:\"+x[\"name\"] + \".游戏描述:\" +x[\"description\"] +\".主机配置建议：\"+ x[\"recommendation\"])\n",
    "        print(response)\n",
    "        url = x[\"url\"].split('?')[0]\n",
    "        urldata = requests.get(url).content\n",
    "        a = io.imread(url)\n",
    "        plt.imshow(a)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d42291f-9fef-4110-81c3-d461b7c23449",
   "metadata": {},
   "outputs": [],
   "source": [
    "Using the above function `similarity_search` , lets do some search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3445405f-2ba3-44d0-b5bf-0bf053178acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_search(\"多人射击游戏\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
